{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Load metadata and GO data, clean, and merge together\n",
    "\n",
    "```\n",
    "Dustin Michels\n",
    "November 2017\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from pandas.plotting import parallel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../../data/'\n",
    "go_data_path = data_path + 'go_downloads/'\n",
    "tax_data_path = data_path + 'taxonomy'\n",
    "img_path = '../imgs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions for Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get / Clean Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_df():\n",
    "    \n",
    "    # Get and clean project meta data\n",
    "    meta_df = pd.read_csv(data_path + \"project_metadata_functional.csv\")\n",
    "\n",
    "    # Make column names neater\n",
    "    meta_df.columns = meta_df.columns.str.strip()\n",
    "    meta_df.columns = meta_df.columns.str.lower()\n",
    "    meta_df.columns = meta_df.columns.str.replace(' ', '_')\n",
    "    meta_df.rename(columns={'sample_details':'zone'}, inplace=True)\n",
    "\n",
    "    # Split lat and long into seperate columns\n",
    "    meta_df['lat'] = meta_df['lat/long'].str.split(',', 1).str[0]\n",
    "    meta_df['long'] = meta_df['lat/long'].str.split(',', 1).str[1]\n",
    "\n",
    "    # Clean up 'region' and 'zone' columns\n",
    "    meta_df['region'] = meta_df['region'].str.strip()\n",
    "    meta_df['zone'] = meta_df['zone'].str.strip()\n",
    "\n",
    "    # Indicate categorical data\n",
    "    meta_df['region'] = meta_df['region'].astype('category')\n",
    "    meta_df['zone'] = meta_df['zone'].astype('category')\n",
    "    meta_df['run_id'] = meta_df['run_id'].astype('category')\n",
    "\n",
    "    # Drop a few categories\n",
    "    meta_df.drop(\n",
    "        ['downloaded','link_to_info', 'student', 'lat/long'],\n",
    "        axis=1, inplace=True)\n",
    "    \n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get / Clean GO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_helper(idx):\n",
    "    \"\"\"Helper function for parsing GO CSVs\"\"\"\n",
    "    \n",
    "    filenames = meta_df['filename']\n",
    "    names = ['go_id', 'name', 'namespace', 'read_count']\n",
    "\n",
    "    # Read GO csv (for given index)\n",
    "    filepath = f\"{go_data_path}{filenames[idx]}\"\n",
    "    df = pd.read_csv(\n",
    "        filepath, header=None, names=names)\n",
    "    \n",
    "    # Add run_id column\n",
    "    df.insert(0, 'run_id', meta_df['run_id'][idx])\n",
    "    \n",
    "    # Sort by read_count\n",
    "    df.sort_values('read_count', ascending=False, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Add read_percent column, based on read_count\n",
    "    read_sum = df['read_count'].sum()\n",
    "    df['read_percent'] = (df['read_count']/read_sum)\n",
    "    \n",
    "    # Drop some columns\n",
    "    df.drop(['go_id','read_count'], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_GO_df():\n",
    "    \"\"\"Call helper function with all GO annotations,\n",
    "    concatenating resulting dataframes together\n",
    "    \"\"\"\n",
    "    \n",
    "    df = get_df_helper(0)\n",
    "    for i in range(1, len(meta_df)):\n",
    "        new_df = get_df_helper(i)\n",
    "        df = pd.concat([df, new_df])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Indicate categorical data\n",
    "    df['run_id'] = df['run_id'].astype('category')\n",
    "    df['namespace'] = df['namespace'].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get / Clean Taxonomy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tax_df():\n",
    "    \"\"\"Read tax_summary.csv and into pandas\n",
    "    and clean data into tiday format\"\"\"\n",
    "    \n",
    "    mapping_dict = {\n",
    "        '00_SrnOcean_DCM':'ERR599104',\n",
    "        '01_SrnOcean_SURF':'ERR599090',\n",
    "        '02_SrnOcean_MESO':'ERR599008',\n",
    "        '03_SPac_DCM':'ERR598948',\n",
    "        '04_SPac_SURF':'ERR598992',\n",
    "        '05_SPac_MESO':'ERR598999',\n",
    "        '06_NPac_DCM':'ERR598995',\n",
    "        '07_NPac_MESO':'ERR598980',\n",
    "        '08_NPac_SURF':'ERR599142',\n",
    "        '09_NAtl_SURF':'ERR599078',\n",
    "        '10_AraSea_MESO':'ERR599031'\n",
    "    }\n",
    "    samples = list(mapping_dict.keys())\n",
    "    run_id = list(mapping_dict.values())\n",
    "\n",
    "    tax_df = pd.read_csv(f\"{tax_data_path}/tax_summary.csv\")\n",
    "    tax_df = tax_df[tax_df['taxlevel']==2]\n",
    "\n",
    "    tax_df.drop(\n",
    "        ['taxlevel', 'daughterlevels', 'rankID','total'],\n",
    "        axis=1, inplace=True)\n",
    "    \n",
    "    # Convert counts to percents\n",
    "    for samp in samples:\n",
    "        tax_df[samp] = tax_df[samp] / tax_df[samp].sum()\n",
    "\n",
    "    # Fix names\n",
    "    cols = ['taxon'] + run_id\n",
    "    tax_df.columns = cols\n",
    "    \n",
    "    # Restructure\n",
    "    tax_df = tax_df.melt(\n",
    "        id_vars='taxon', var_name='run_id',\n",
    "        value_name='tax_percent')\n",
    "    \n",
    "    # Sort columns\n",
    "    tax_df = tax_df.sort_index(axis=1)\n",
    "    \n",
    "    return tax_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_func(meta_df, go_df):\n",
    "    \"\"\"Merge go_df, meta_df together, using run_id\"\"\"\n",
    "    \n",
    "    # Merge meta/GO\n",
    "    full_df = go_df.merge(meta_df, on='run_id')\n",
    "    full_df.drop('filename', axis=1, inplace=True)\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_tax(meta_df, tax_df):\n",
    "    \"\"\"Merge tax_df, meta_df together, using run_id\"\"\"\n",
    "    \n",
    "    full_df = tax_df.merge(meta_df, on='run_id')\n",
    "    full_df.drop('filename', axis=1, inplace=True)\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Top-25 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_25_func(full_df):\n",
    "    \"\"\"Get superset of 25 most abundant functional groups\n",
    "    shared by all samples. This becomes 29 functional groups.\n",
    "    Also: truncates func group names at 35 characters.\"\"\"\n",
    "\n",
    "    grouped_df = full_df.groupby('run_id').head(n=25)\n",
    "    names = grouped_df.name.unique()\n",
    "\n",
    "    # Select entries in full_df where name is one of the 29\n",
    "    top_df = full_df[full_df['name'].isin(names)]\n",
    "\n",
    "    # Make a deep copy (instead of using a slice of full_df)\n",
    "    top_df = top_df.copy(deep=True)\n",
    "    \n",
    "    # Truncate function names at 35 characters\n",
    "    top_df['name'] = top_df['name'].apply(\n",
    "    lambda x: (x[:35] + '...') if len(x) > 38 else x)\n",
    "    \n",
    "    return top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_25_tax(full_df):\n",
    "    \"\"\"Get superset of 25 most abundant functional groups\n",
    "    shared by all samples. This becomes 29 functional groups.\n",
    "    Also: truncates func group names at 35 characters.\"\"\"\n",
    "\n",
    "    # Grab 25 largest, by taxonomy percent, for each group\n",
    "    s = full_df.groupby('run_id')['tax_percent'].nlargest(25)\n",
    "    \n",
    "    # Query full dataframe for matching indicies\n",
    "    top_df = full_df.iloc[s.index.droplevel(0)]\n",
    "    \n",
    "    # Make a deep copy (instead of using a slice of full_df)\n",
    "    top_df = top_df.copy(deep=True)\n",
    "    \n",
    "    return top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meta_df = get_meta_df()\n",
    "go_df = get_GO_df()\n",
    "tax_df = get_tax_df()\n",
    "\n",
    "full_go = merge_func(meta_df, go_df)\n",
    "full_tax = merge_tax(meta_df, tax_df)\n",
    "\n",
    "top_go = top_25_func(full_go)\n",
    "top_tax = top_25_tax(full_tax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
